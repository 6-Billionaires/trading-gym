"""
1. "episode_type" : 0 (for now, there is only one episode type.)
2. data shape
    { "episode_idx" : "episode_data" : {
                                                "meta" : {
                                                    "ticker" : "AAPL",
                                                    "date"   : "20180501"
                                                },
                                                "quote" : dataframe generated by pandas after reding csv,
                                                "order" : dataframe generated by pandas after reding csv,
                                                }
                                         }
"""
import logging
from gym.core import Env
import pandas as pd
import numpy as np
import glob
from  util.Exception import TradingException
import random
import datetime
import math
import config
import os
from collections import deque
import pickle
import os.path
import logging
import time

c_delim = config.GYM['Delimiter']
dir_gym_home = config.GYM['HOME']

def make_dir(*d_args):
    dir = ''
    for i, d in enumerate(d_args):
        if d[-1] != c_delim and i != len(d_args)-1:
            dir += d + c_delim
        else:
            dir += d
    return dir


def runtime(f):
    def wrapper(*args, **kwargs):
        import timeit
        start = timeit.default_timer()
        f(*args, **kwargs)
        end = timeit.default_timer()
        print('executed time : ', end - start)
        return f(*args, **kwargs)
    return wrapper


def load_ticker_yyyymmdd_list_from_directory(dir):
    """
    loads all pickle file lists from dir
    :param dir : the directory where all pickle files to be read exist
    :return: list including all pickle files
    """
    ticker_yyyymmdd_list = []
    for idx, item in enumerate(glob.glob(make_dir(dir, '*.pickle'))):
        ticker_yyyymmdd_list.append((item.split(c_delim)[-1][0:8], item.split(c_delim)[-1][9:15]))
    return ticker_yyyymmdd_list


def load_data_from_directory(dir, episode_type, max_n_episode=None):
    """
    load every equities data out of a directory
    :param dir : the directory where all csv files to be read exist
    :param episode_type: for now, it has only 0.
    :param max_n_episode: It is just for quick test.you can give maximum row count while reading file.
    :return:
    """
    l = []

    for idx, item in enumerate(glob.glob(make_dir(dir, episode_type, '*'))):
        for pf in glob.glob(make_dir(item, '/*-order.csv')):

            if max_n_episode is not None and max_n_episode <= idx:
                break

            f = pf.split('\\')[-1]
            f = f.split('/')[-1]
            current_ticker = f.split('-')[1]
            current_date = f.split('-')[2]

            d = load_single_data_from_pair_files(dir, episode_type, current_ticker, current_date)
            # print(d)
            l.append(d)
    return l

def load_single_data_from_pair_files(dir, episode_type, ticker, yyyymmdd):
    """
    load single equity data out of ticker file which can be determined only with ticker and yyyymmdd
    :param dir : full path of directory where all pickle files to be read exist
    :param episode_type: episode type default 0
    :param ticker: ticker code which it will read
    :param yyyymmdd : a day when it traded
    :return: data of the equity
    """
    d_order = pd.DataFrame()
    d_quote = pd.DataFrame()
    d_meta = {}

    f_order = make_dir(dir, episode_type, ticker, episode_type+'-'+ticker+'-'+yyyymmdd+'-order.csv')
    f_quote = make_dir(dir, episode_type, ticker, episode_type+'-'+ticker+'-'+yyyymmdd+'-quote.csv')
    d_meta = {'ticker': ticker, "date": yyyymmdd}  # 1

    try :
        d_order = pd.read_csv(f_order, index_col=0, parse_dates=True)  #2
    except Exception as e:
        print('{} file caused error {}'.format(f_order,e))
    try:
        d_quote = pd.read_csv(f_quote, index_col=0, parse_dates=True)  #2
    except Exception as e:
        print('{} file caused error {}'.format(f_quote,e))

    d_episode_data = {}
    d_episode_data['meta'] = d_meta
    d_episode_data['quote'] = d_quote
    d_episode_data['order'] = d_order

    return d_episode_data


episode_type = '0'
ticker = '002150'
yyyymmdd = '20180417'

if __name__ == '__main__':
    # d = 'D:\\dev\\workspace\\trading-agent\\buy_signal_agent\\verystrongjoe'
    # d = 'C:\\Git\\trading-agent\\buy_signal_agent\\verystrongjoe'
    # print(load_single_data_from_pair_files(episode_type,ticker, yyyymmdd))
    # print(load_data_from_directory(episode_type, 10))

    import config
    d = config.BSA_PARAMS['CSV_DIR_FOR_CREATING_PICKLE_TRAINING']

    print(load_ticker_yyyymmdd_list_from_directory(d))