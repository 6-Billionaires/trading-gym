import logging
from gym.core import Env
import pandas as pd
import numpy as np
import glob
from util.Exception import TradingException
import  random

class TradingGymEnv(Env):

    episodes_data = {}
    # orders = []  # save orders of episode type
    # quotes = []  # save quotes of episode type
    # current_idx = 0 # index number to point out the current episode to run episode

    # every agent has their own constraints to be managed by trading gym itself.
    p_agent_max_num_of_allowed_transaction = 10
    p_agent_current_num_transaction = 0
    p_agent_current_step_timestamp = None # this is index data to find data through each rows in csv file for sending data to a agent
    p_agent_current_agent_ref_idx = 0

    """
    This class's super class is from OpenAI Gym and extends to provide trading environment

    # reference
        - keyword for trading
            . http://www.fo24.co.kr/bbs/print_view.html?id=167497&code=bbs203
        - doc
            . http://docs.python-guide.org/en/latest/writing/documentation/
        - style guide to write comment ( or docstring)
            . https://medium.com/@kkweon/%ED%8C%8C%EC%9D%B4%EC%8D%AC-doc-%EC%8A%A4%ED%83%80%EC%9D%BC-%EA%B0%80%EC%9D%B4%EB%93%9C%EC%97%90-%EB%8C%80%ED%95%9C-%EC%A0%95%EB%A6%AC-b6d27cd0a27c
            . http://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html
    """
    def _is_done(self):
        """
        check whether or not this episode is ended.

        Environment side
        ========================
        . current step exceeds in max_steps
        . exceed episode time bound

        Agent side
        ========================
        . lose all money agent has (= no balance)
        . exceed the count of available transaction

        :return: True or False

        """
        if self.p_agent_current_num_transaction > self.p_agent_max_num_of_allowed_transaction :
            return True
        elif self._current_agent_time_stamp > self.episode_duration_min:
            return True
        else:
            return False


    def __init__(self, episode_type=None, episode_duration_min = 10, step_interval='1s', stop_loss=None,
                 balanace = None, max_num_of_transaction=None, obs_transform=None):
        """
        Here is most important part to configure Environment with various parameters.
        First of all, it will load data into memory.
        Args:
            episode type
                0 : treat equity which reached upper limit yesterday ( in development )
                1 : treat equity which start 5% higher price compared to close price yesterday ( not development yet )
            episode_duration_min
                this parameter will limit episode time
            step_interval
                this value is consist of number and unit of time ('s' for second, 'm' for minute, 'h' for hour ,'d' for day)
        """
        self.episode_type = None
        self.episode_duration_min = 390  # this parameter is belong to episode type so that it isn't necessary anymore.

        self.n_actions = None
        self.state_shape = None
        self.interval = 1   # 1 second
        self.ob_transform = obs_transform

        # TODO : load all data of ticker from database or file into memory
        """
        It loads csv files based on its episode type. Before, we need to ensure that those csv files have to locate in a 
        directory where trading-episode-filter gathered according to rules of episode type
        ##  csv format is look like below
            episode_type-AAPL-yyyymmdd-quote.csv, 
            episode_type-AAPL-yyyymmdd-order.csv
        """

        self.episode_idx = 0

        # TODO : add directory where episode csv data exits
        # data/episode_type/ticker/episode_type-ticker-yyyymmdd.csv
        for item in glob.glob(episode_type + '-*.csv') :
            """
            1. condition
                for now, there is only one episode type. 
                 - "episode_type" : 0
               
            2. data shape
                {
                    "episode_idx" : 0, 
                    "episode_data" : [
                        "meta" : {
                            "ticker" : "AAPL",
                            "Date"   : "20180501"
                        },
                        "quote" : dataframe generated by pandas after reding csv 
                        "order" : dataframe generated by pandas after reding csv
                    }
                }
            """

            # TODO : parse ticker out of filename
            current_ticker = 'AAPL'

            # TODO : parse data out of filename
            current_date = '20180505'

            d_meta = {'ticker' : current_date, "date" : current_date} # 1

            if item.endswith('-order.csv'):
                d_order = pd.read_csv(item) # 2
            elif item.endswith('-quotes.csv'):
                d_quote = pd.read_csv(item) # 3
            else:
                raise TradingException('it found out a file followed by wrong convention.')

            d_episode_data = {}
            d_episode_data['meta'] = d_meta
            d_episode_data['quote'] = d_quote
            d_episode_data['order'] = d_order

            self.episodes_data[self.episode_idx] = d_episode_data
            self.episode_idx = self.episode_idx + 1
            self.episode_timestamp = '090601'   # start timestamp in each episode

        # for now, episode type is not considered.
        self.p_agent_current_agent_ref_idx = random.randint(0, self.episode_idx)


    def _rewards(self):
        """
        we don't need this function since this will be replaced by its agent decision.
        @return:
        """
        pass

    def _get_observation(self):
        """
        Obesrvation information
        ===============================
        0. time : it is important feature which means timestamp that environment has when agent requested
        1. bid / ask quote top 10
        2. open high close low based on step_interval in env
        3. 3 closest from present price
        4. spot price : price in present
        5. percentage : increase or decrease percentage compared to its close price of yesterday
        6. cumulated_volume
        7. cumulated_transaction_money

        ## mean_transaction_cost, strongnessTosucceed, ransaction_money_by_unit_time, volume_by_unit_time
        ## consideration !!!
        Important thing is that we don't consider any values that agent only knows such as balance,
        """
        return []


    def step(self, action):
        """
        Here is the interface to be called by its agent.
        _get_observation needs to be transformed using transform observation that __init__ received.

        Args:
            action (object): for now, action is simple! 1 or -1 ( buy all or sell all )
        Returns:
            observation (object): agent's observation of the current environment
            reward (float) : amount of reward returned after previous action
            done (boolean): whether the episode has ended, in which case further step() calls will return undefined results
            info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)
        """
        self._current_aget_step_timestamp =


        raise NotImplementedError()

    def reset(self):
        """Reset the state of the environment and returns an initial observation.

        here we will reset agent's enviroment to restart.
        for now, we need to have its database to load and the status will go back to its first status like it called init

        everytime, it needs to reset index to reference which index of episode data agent use training data.

        Returns:
            numpy.array: The initial observation of the space. Initial reward is assumed to be 0.
        """
        self.p_agent_current_agent_ref_idx = random.randint(0, self.episode_idx)


        raise NotImplementedError()


    def render(self):
        """
        Render the environment.
        display agent and gym's status based on a user configures
        """
        logging.info(self._get_status())
        pass


